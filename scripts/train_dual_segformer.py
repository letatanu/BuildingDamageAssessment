'''\npython scripts/train_dual_segformer.py \\\n    --config_file datasets/configs/segformer_xBD.py \\\n    --train_dir data/xBD_tiled \\\n    --val_dirs data/xBD_tiled data/CRASAR-tiles\n'''\n\nimport os, sys, json, math, random\nfrom pathlib import Path\nfrom PIL import Image\nimport torch\nimport torch.nn as nn\nimport numpy as np\nfrom transformers import Trainer, set_seed\nfrom torch.utils.data import Dataset\nfrom sklearn.metrics import confusion_matrix\n\n# Import FloodNet dataset loaders and Models\nfrom nh_datasets.floodnet import FloodNetSegDataset\nfrom models.dual_siamese_segformer import DualHeadSiameseSegFormer\nfrom transformers import SegformerImageProcessor\n\nfrom scripts.utils import (\n    setup_devices_autodetect,\n    safe_training_args,\n    compute_mIoU,\n    choose_resume_checkpoint,\n    parse_args,\n)\n\n# ---------------------------------------------------------\n# 0) Dataset Wrappers & Auto-Detect Factory\n# ---------------------------------------------------------\nclass PairedXBDFloodNetDataset(Dataset):\n    \"\"\" Custom Paired loader that does not require pre-labels and synchronizes augmentations \"\"\"\n    def __init__(self, root_dir, split_base, image_processor, num_classes=5, augment=False, image_size=512):\n        self.root = Path(root_dir)\n        self.split_base = split_base\n        self.ip = image_processor\n        self.augment = augment\n        self.image_size = image_size\n        self.num_classes = num_classes\n\n        self.pre_img_dir = self.root / f\"{split_base}_pre\" / f\"{split_base}_pre-org-img\"\n        self.post_img_dir = self.root / f\"{split_base}\" / f\"{split_base}-org-img\"\n        self.post_lbl_dir = self.root / f\"{split_base}\" / f\"{split_base}-label-img\"\n\n        if not self.pre_img_dir.is_dir(): raise FileNotFoundError(f\"Missing pre image dir: {self.pre_img_dir}\")\n        if not self.post_img_dir.is_dir(): raise FileNotFoundError(f\"Missing post image dir: {self.post_img_dir}\")\n        if not self.post_lbl_dir.is_dir(): raise FileNotFoundError(f\"Missing post label dir: {self.post_lbl_dir}\")\n\n        IMG_EXTS = {\".jpg\", \".jpeg\", \".JPG\", \".JPEG\", \".png\", \".PNG\"}\n        self.samples = []\n\n        for fname in os.listdir(self.post_img_dir):\n            stem, ext = os.path.splitext(fname)\n            if ext not in IMG_EXTS:\n                continue\n                \n            post_img_p = self.post_img_dir / fname\n            \n            # 1. Match Post Label\n            post_lbl_p = None\n            for ext2 in IMG_EXTS:\n                cand = self.post_lbl_dir / f\"{stem}_lab{ext2}\"\n                if cand.exists():\n                    post_lbl_p = cand\n                    break\n            if not post_lbl_p:\n                continue\n                \n            # 2. Match Pre Image\n            pre_stem = stem.replace(\"post_disaster\", \"pre_disaster\")\n            pre_img_p = None\n            for ext3 in IMG_EXTS:\n                cand = self.pre_img_dir / f\"{pre_stem}{ext3}\"\n                if cand.exists():\n                    pre_img_p = cand\n                    break\n            \n            if pre_img_p and pre_img_p.exists():\n                self.samples.append((pre_img_p, post_img_p, post_lbl_p))\n\n        if len(self.samples) == 0:\n            raise RuntimeError(f\"No paired matching samples found between {self.pre_img_dir} and {self.post_img_dir}\")\n            \n        self.rng = random.Random(1337)\n\n    def __len__(self):\n        return len(self.samples)\n\n    def __getitem__(self, idx):\n        pre_img_p, post_img_p, post_lbl_p = self.samples[idx]\n\n        pre_img = Image.open(pre_img_p).convert(\"RGB\")\n        post_img = Image.open(post_img_p).convert(\"RGB\")\n        lab = Image.open(post_lbl_p)\n        if lab.mode != \"L\":\n            lab = lab.convert(\"L\")\n\n        # Synchronously mirror Pre, Post, and Label\n        if self.augment and self.rng.random() < 0.5:\n            pre_img = pre_img.transpose(Image.FLIP_LEFT_RIGHT)\n            post_img = post_img.transpose(Image.FLIP_LEFT_RIGHT)\n            lab = lab.transpose(Image.FLIP_LEFT_RIGHT)\n\n        pre_img = pre_img.resize((self.image_size, self.image_size), Image.BILINEAR)\n        post_img = post_img.resize((self.image_size, self.image_size), Image.BILINEAR)\n        lab = lab.resize((self.image_size, self.image_size), Image.NEAREST)\n\n        lab_np = np.array(lab, dtype=np.int64)\n\n        encoded_pre = self.ip(images=pre_img, return_tensors=\"pt\")\n        encoded_post = self.ip(images=post_img, return_tensors=\"pt\")\n\n        # FORCE CONTIGUOUS CLONES TO PREVENT CUDA MISALIGNED ADDRESS CRASH\n        return {\n            \"pixel_values_pre\": encoded_pre[\"pixel_values\"].squeeze(0).clone().contiguous(),\n            \"pixel_values_post\": encoded_post[\"pixel_values\"].squeeze(0).clone().contiguous(),\n            \"labels\": torch.from_numpy(lab_np).clone().contiguous(),\n            \"id\": post_img_p.stem\n        }\n\nclass SingleImageFloodNetDataset(Dataset):\n    \"\"\" Wraps single-image datasets (e.g., CRASAR) providing a blank pre-disaster tensor \"\"\"\n    def __init__(self, root_dir, split, image_processor, num_classes=5, augment=False):\n        self.dataset = FloodNetSegDataset(\n            root=root_dir, split=split, image_processor=image_processor, augment=augment, num_classes=num_classes\n        )\n\n    def __len__(self):\n        return len(self.dataset)\n\n    def __getitem__(self, idx):\n        item = self.dataset[idx]\n        pixel_values_post = item[\"pixel_values\"]\n        pixel_values_pre = torch.zeros_like(pixel_values_post)\n\n        # FORCE CONTIGUOUS CLONES\n        return {\n            \"pixel_values_pre\": pixel_values_pre.clone().contiguous(),\n            \"pixel_values_post\": pixel_values_post.clone().contiguous(),\n            \"labels\": item[\"labels\"].clone().contiguous(),\n            \"id\": item[\"id\"]\n        }\n\ndef create_dataset(root_dir, split_base, image_processor, num_classes=5, augment=False):\n    pre_dir = os.path.join(root_dir, f\"{split_base}_pre\")\n    post_dir = os.path.join(root_dir, f\"{split_base}\")\n    \n    if os.path.isdir(pre_dir) and os.path.isdir(post_dir):\n        print(f\"[*] Detected Paired Dataset at {root_dir} (Split base: {split_base})\")\n        return PairedXBDFloodNetDataset(root_dir, split_base, image_processor, num_classes, augment)\n    else:\n        print(f\"[*] Detected Single-Image Dataset at {root_dir} (Split: {split_base})\")\n        return SingleImageFloodNetDataset(root_dir, split_base, image_processor, num_classes, augment)\n\n# ---------------------------------------------------------\n# 1) Custom Model Wrapper for Hugging Face Trainer\n# ---------------------------------------------------------\nclass XBDDualSiameseModel(nn.Module):\n    def __init__(self, backbone=\"nvidia/mit-b2\", num_damage_classes=5):\n        super().__init__()\n        self.model = DualHeadSiameseSegFormer(backbone=backbone, num_damage_classes=num_damage_classes)\n        self.loss_loc = nn.CrossEntropyLoss()\n        self.loss_cls = nn.CrossEntropyLoss(ignore_index=0)\n\n    def forward(self, pixel_values_pre, pixel_values_post, labels=None, **kwargs):\n        logits_loc, logits_cls = self.model(pixel_values_pre, pixel_values_post)\n        loss = None\n        if labels is not None:\n            labels_loc = (labels > 0).long()\n            loss_loc = self.loss_loc(logits_loc, labels_loc)\n            loss_cls = self.loss_cls(logits_cls, labels)\n            loss = loss_loc + loss_cls\n\n        return {\"loss\": loss, \"logits_loc\": logits_loc, \"logits_cls\": logits_cls}\n\n# ---------------------------------------------------------\n# 2) Custom Collate & Metrics Function\n# ---------------------------------------------------------\ndef collate_fn(batch):\n    # EXTRA CONTIGUOUS SAFEGUARDS ON BATCHING\n    return {\n        \"pixel_values_pre\": torch.stack([b[\"pixel_values_pre\"] for b in batch], dim=0).contiguous(),\n        \"pixel_values_post\": torch.stack([b[\"pixel_values_post\"] for b in batch], dim=0).contiguous(),\n        \"labels\": torch.stack([b[\"labels\"] for b in batch], dim=0).contiguous()\n    }\n\ndef metrics_fn(eval_pred):\n    logits_cls = eval_pred.predictions[1] if isinstance(eval_pred.predictions, tuple) else eval_pred.predictions\n    labels = eval_pred.label_ids\n    \n    metrics = compute_mIoU((logits_cls, labels), num_classes=5, ignore_index=0)\n    \n    preds = np.argmax(logits_cls, axis=1).flatten()\n    targets = labels.flatten()\n    \n    valid_mask = (targets != 0)\n    preds_valid = preds[valid_mask]\n    targets_valid = targets[valid_mask]\n    \n    cm = confusion_matrix(targets_valid, preds_valid, labels=range(5))\n    \n    print(\"\\n\" + \"=\"*50)\n    print(\"VALIDATION CONFUSION MATRIX (Pixels)\")\n    print(\"Rows = Ground Truth | Columns = Predictions\")\n    print(f\"{'':>12} | {'Bg (0)':>10} | {'No Dam (1)':>10} | {'Minor (2)':>10} | {'Major (3)':>10} | {'Destr (4)':>10}\")\n    print(\"-\" * 75)\n    class_names = [\"Bg (0)\", \"No Dam (1)\", \"Minor (2)\", \"Major (3)\", \"Destr (4)\"]\n    \n    for i in range(1, 5):  \n        print(f\"{class_names[i]:>12} | {cm[i][0]:10d} | {cm[i][1]:10d} | {cm[i][2]:10d} | {cm[i][3]:10d} | {cm[i][4]:10d}\")\n    print(\"=\"*50 + \"\\n\")\n    \n    return metrics\n\n# ---------------------------------------------------------\n# 3) Training Loop Setup\n# ---------------------------------------------------------\ndef train(args, custom_args, ddp_kwargs):\n    processor = SegformerImageProcessor.from_pretrained(args.model_name)\n\n    print(f\"\\n--- Loading Training Data ---\")\n    train_dir = custom_args[\"train_dir\"] or args.data_root\n    train_ds = create_dataset(\n        root_dir=train_dir, split_base=args.train_split, \n        image_processor=processor, augment=True, num_classes=5\n    )\n\n    print(f\"\\n--- Loading Validation Data ---\")\n    eval_datasets = {}\n    val_dirs = custom_args[\"val_dirs\"] if custom_args[\"val_dirs\"] else [args.data_root]\n    \n    for v_dir in val_dirs:\n        ds_name = os.path.basename(os.path.normpath(v_dir))\n        eval_datasets[ds_name] = create_dataset(\n            root_dir=v_dir, split_base=args.val_split, \n            image_processor=processor, augment=False, num_classes=5\n        )\n\n    model = XBDDualSiameseModel(backbone=args.model_name, num_damage_classes=5)\n\n    steps_per_epoch = math.ceil(len(train_ds) / (args.batch_size * max(1, torch.cuda.device_count())))\n    save_steps = max(steps_per_epoch, 100)\n\n    first_val_name = list(eval_datasets.keys())[0]\n    best_metric_name = f\"{first_val_name}_mIoU\"\n\n    training_args = safe_training_args(\n        output_dir=args.output_dir,\n        per_device_train_batch_size=args.batch_size,\n        per_device_eval_batch_size=args.eval_batch_size,\n        learning_rate=args.lr,\n        weight_decay=args.weight_decay,\n        num_train_epochs=args.epochs,\n        eval_strategy=\"epoch\",\n        save_strategy=\"epoch\",\n        save_steps=save_steps,\n        save_total_limit=args.save_total_limit,\n        load_best_model_at_end=True,\n        metric_for_best_model=best_metric_name, \n        greater_is_better=True,\n        overwrite_output_dir=args.overwrite_output_dir,\n        remove_unused_columns=False, \n        **ddp_kwargs,\n    )\n\n    trainer = Trainer(\n        model=model,\n        args=training_args,\n        train_dataset=train_ds,\n        eval_dataset=eval_datasets, \n        data_collator=collate_fn,\n        compute_metrics=metrics_fn,\n    )\n\n    print(\"\\n--- Starting Training ---\")\n    resume_from = choose_resume_checkpoint(args.resume, args.output_dir)\n    trainer.train(resume_from_checkpoint=resume_from)\n    \n    metrics = trainer.evaluate()\n    print(\"Final Multi-Dataset Evaluation Metrics:\", metrics)\n\n    torch.save(model.model.state_dict(), os.path.join(args.output_dir, \"dual_siamese_best.pth\"))\n    print(\"Training complete. Best checkpoint saved at:\", trainer.state.best_model_checkpoint)\n\n\ndef extract_custom_args():\n    custom_args = {\"train_dir\": None, \"val_dirs\": []}\n    \n    if \"--train_dir\" in sys.argv:\n        idx = sys.argv.index(\"--train_dir\")\n        custom_args[\"train_dir\"] = sys.argv[idx + 1]\n        sys.argv.pop(idx)\n        sys.argv.pop(idx)\n        \n    if \"--val_dirs\" in sys.argv:\n        idx = sys.argv.index(\"--val_dirs\")\n        sys.argv.pop(idx)\n        while idx < len(sys.argv) and not sys.argv[idx].startswith(\"--\"):\n            custom_args[\"val_dirs\"].append(sys.argv[idx])\n            sys.argv.pop(idx)\n            \n    return custom_args\n\ndef main():\n    custom_args = extract_custom_args()\n    args = parse_args()\n\n    mode, local_rank, world_size = setup_devices_autodetect()\n    ddp_kwargs = {}\n    if world_size > 1:\n        ddp_kwargs.update(dict(ddp_find_unused_parameters=False))\n\n    set_seed(args.seed)\n    train(args, custom_args, ddp_kwargs)\n\nif __name__ == \"__main__\":\n    main()\n